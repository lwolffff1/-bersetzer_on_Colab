from transformers import MarianMTModel, MarianTokenizer
from gtts import gTTS
import torch
import os
import json
# BÆ°á»›c 1: Äá»c ná»™i dung tá»« JSON
with open("output.json", "r", encoding="utf-8") as f:
    data = json.load(f)
    ##input_text = data.get("content", "")

if not data:
    print("âŒ File JSON khÃ´ng cÃ³ ná»™i dung Ä‘á»ƒ dá»‹ch.")
    exit()


# Chá»n mÃ´ hÃ¬nh dá»‹ch tá»« Äá»©c sang Anh
model_name = "Helsinki-NLP/opus-mt-de-en"
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)


# Tokenize vÃ  dá»‹ch
for i, article in enumerate(data):
    input_text = article["content"]
inputs = tokenizer([input_text], return_tensors="pt", padding=True, truncation=True)
translation = model.generate(**inputs)
translated_text = tokenizer.batch_decode(translation, skip_special_tokens=True)[0]

print("ğŸ“Œ Báº£n dá»‹ch:", translated_text)

# Chuyá»ƒn thÃ nh giá»ng nÃ³i
tts = gTTS(translated_text, lang='en')
tts.save("output.mp3")

# PhÃ¡t Ã¢m thanh trÃªn local (Windows/macOS/Linux)
if os.name == 'nt':  # Windows
    os.system("start output.mp3")
else:  # macOS/Linux
    os.system("mpg321 output.mp3")

